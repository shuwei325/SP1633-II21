Month <- c(rep(c(1), 10), rep(c(5), 10), rep(c(10), 10), rep(c(15), 10))
Naps <- c(rep(c(3), 10), 2, 3, 2, 1, 2, 3, 2, 3, 2, 3, 2, 2, 2 ,2, 3, 3, 2, 2, 1, 2, 3, 1, 2, 2, 1, 1, 2, 1, 2, 1 )
Napsfactor <- as.factor(Naps)
#Let's assume that infants' performance will get better with time. I altered the possible sampling distributions to reflect this.
scores <- c(runif(10, 1, 7), runif(10, 8, 15), runif(10, 16, 22), runif(10, 23, 30))
dataset <- data.frame(Subs, Month, Naps, scores, Napsfactor)
dataset
#Conditional growth model
tutorial<-lme(scores ~ Month * Naps, random = ~ Month | Subs, data=dataset)
tutorial
tut <- summary(tutorial)
tut
tabl = tut$tTable
tabl
#Conditional growth model
tutorial<-lme(scores ~ Month * Naps, random = ~ Month | Subs, data=dataset)
tutorial
tut <- summary(tutorial)
tabl = tut$tTable
tabl
tutorial<-lme(scores ~ Month * Naps, random = ~ Month | Subs, data=dataset)
tutorial
tut <- summary(tutorial)
tabl = tut$tTable
tabl
tutorial<-lme(scores ~ Month * Naps, random = ~ Month | Subs, data=dataset)
tutorial
tut <- summary(tutorial)
tabl = tut$tTable
tabl
tutorial<-lme(scores ~ Month * Naps, random = ~ Month | Subs, data=dataset)
tutorial
tut <- summary(tutorial)
tabl = tut$tTable
tabl
tutorial<-lme(scores ~ Month * Naps, random = ~ Month | Subs, data=dataset)
tutorial
tut <- summary(tutorial)
tabl = tut$tTable
tabl
tutorial<-lme(scores ~ Month * Naps, random = ~ Month | Subs, data=dataset)
tutorial
tut <- summary(tutorial)
tabl = tut$tTable
tabl
tutorial<-lme(scores ~ Month * Naps, random = ~ Month | Subs, data=dataset)
tutorial
tut <- summary(tutorial)
tabl = tut$tTable
tabl
tutorial<-lme(scores ~ Month * Naps, random = ~ Month | Subs, data=dataset)
tutorial
tut <- summary(tutorial)
tabl = tut$tTable
tabl
library(ggplot2)
plot<- ggplot(dataset, aes(x=Month, y=scores,  color=Napsfactor, shape = Napsfactor, group = Subs), xlim(1, 15), ylim(0, 25), xlab(Month) ) +
geom_point()+
geom_line(color="grey")
plot + scale_x_continuous(name="Age (in months)", limits=c(1, 15), breaks =c(1,5,10,15)) +
scale_y_continuous(name="Scores", limits=c(0, 30))
#Create a new data set
Subs <- rep(c(seq(1:10)), 4)
Month <- c(rep(c(1), 10), rep(c(5), 10), rep(c(10), 10), rep(c(15), 10))
Naps <- c(rep(c(3), 10), 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3 ,2,2,  2, 2,2,1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1)
Napsfactor <- as.factor(Naps)
secondscores <- c(runif(10, 1, 10), runif(5, 5, 10),runif(5, 9, 17), runif(3, 10, 15), runif(5, 14, 22), runif(2, 20, 25), runif(5, 18, 23), runif(4,22, 27), runif(1, 27, 30) )
seconddataset <- data.frame(Subs, Month, Naps, secondscores, Napsfactor)
#save(seconddataset, file="horger2.RData")
seconddataset
#Summary stats from our first dataset
demos <- dataset %>%
group_by(Month, Naps) %>%
summarise(mean_score = mean(scores, na.rm=TRUE))
demos
#Summary stats from our second dataset
seconddemos <- seconddataset %>%
group_by(Month, Naps) %>%
summarise(mean_secondscore = mean(secondscores, na.rm=TRUE))
print(demos)
print(demos)
secondtutorial <- lme(secondscores ~ Month * Naps, random = ~ Month | Subs, data=seconddataset)
secondtutorial
#Summary stats from our second dataset
seconddemos <- seconddataset %>%
group_by(Month, Naps) %>%
summarise(mean_secondscore = mean(secondscores, na.rm=TRUE))
print(demos)
secondtutorial <- lme(secondscores ~ Month * Naps, random = ~ Month | Subs, data=seconddataset)
?sim_sarima
??sim_sarima
library(spacetime)
getOption("device")
plot(c(1,2,3))
options(device = "windows")
plot(c(1,2,3))
options(device = "RStudioGD")
plot(c(1,2,3))
getOption("device")
options(device = "windows")
getOption("device")
plot(c(1,2,3))
options(device = "windows")
plot(c(1,2,3))
getOption("device")
options(device = "RStudioGD")
plot(c(1,2,3))
getOption("device")
plot(c(1,2,3))
options(device = "RStudioGD")
getOption("device")
blogdown::serve_site()
50*0.95
library(NanoICPMS.App)
run_NanoICPMS_app()
citation()
citation("ggplot2")
citation("ggplot2","forecast")
citation(c("ggplot2","forecast"))
citation("ggplot2")
library(shiny); source('D:/Downloads/test downloading zip 1.R')
detach("package:utils", unload = TRUE)
library(utils)
detach("package:utils", unload = TRUE)
library(shiny)
runApp(
list(server = function(input, output) {
output$downloadData <- downloadHandler(
filename = function() {
paste("output", "zip", sep=".")
},
content = function(fname) {
fs <- c()
#tmpdir <- tempdir()
#setwd(tempdir())
for (i in c(1,2,3,4,5)) {
path <- paste0("sample_", i, ".csv")
fs <- c(fs, path)
write(i*2, path)
}
zip(zipfile=fname, files=fs)
},
contentType = "application/zip"
)
}
, ui = fluidPage(
titlePanel(""),
sidebarLayout(
sidebarPanel(
downloadButton("downloadData", label = "Download")
),
mainPanel(h6("Sample download", align = "center"))
)
))
)
library(utils)
library(shiny)
runApp(
list(server = function(input, output) {
output$downloadData <- downloadHandler(
filename = function() {
paste("output", "zip", sep=".")
},
content = function(fname) {
fs <- c()
#tmpdir <- tempdir()
#setwd(tempdir())
for (i in c(1,2,3,4,5)) {
path <- paste0("sample_", i, ".csv")
fs <- c(fs, path)
write(i*2, path)
}
zip(zipfile=fname, files=fs)
},
contentType = "application/zip"
)
}
, ui = fluidPage(
titlePanel(""),
sidebarLayout(
sidebarPanel(
downloadButton("downloadData", label = "Download")
),
mainPanel(h6("Sample download", align = "center"))
)
))
)
?downloadHandler
?bmp
detach("package:grDevices", unload = TRUE)
library(grDevices)
?zip
?dev.off
?get
?bmp
library(GAMLSS)
install.packages("gamlss")
library(gamlss)
library(boot)
data("abdom")
abdom
head(abdom)
fit2 <- gamlss(y~poly(x,2), sigma.fo=~x, data=abdom, trace=FALSE,
family=LO)
fit3 <- gamlss(y~poly(x,3), sigma.fo=~x, data=abdom, trace=FALSE,
family=LO)
AIC(fit2, fit3)
LR.test(fit2, fit3)
library(boot)
# a new data.frame with fitted mu and sigma
abdomA <- data.frame(abdom, fmu=fitted(fit3),
fsigma=fitted(fit3, "sigma"))
abdomA
head(abdomA)
# a new data.frame with fitted mu and sigma
abdomA <- data.frame(abdom, fmu=fitted(fit3),
fsigma=fitted(fit3, "sigma"))
data=abdomA
i=1
d<-data # the data
d
as.character(sys.call())
sys.call())
sys.call()
# function to save the mu coefficients
abd.funA <- function(data, i)#i is the index for bootstrapping
{
d<-data # the data
#omit the first
d$y <- if ("original"%in%as.character(sys.call())) d$y
#simulate y
else rLO(dim(d)[1], mu=d$fmu, sigma=d$fsigma)
coef(update(fit3, data=d)) # fit and get the coef for mu
}
(abd.T1<-boot(abdomA,abd.funA, R=999))
abd.T1
plot(abd.T1, index=4)# parameter 4
boot.ci(abd.T1, index=c(4,1))
?rLO
fitted(fit3)
abdomA
?boot
data
d<-data # the data
#omit the first
d$y <- if ("original"%in%as.character(sys.call())) d$y
#simulate y
else rLO(dim(d)[1], mu=d$fmu, sigma=d$fsigma)
#omit the first
d$y <- if ("original"%in%as.character(sys.call())) d$y
#omit the first
d$y <- if ("original"%in%as.character(sys.call())) {d$y
} else {rLO(dim(d)[1], mu=d$fmu, sigma=d$fsigma)}
d$y
d
head(d)
data
# Libraries
library(ggplot2)
library(dplyr)
# Dummy data
data <- data.frame(
day = as.Date("2017-06-14") - 0:364,
value = runif(365) + seq(-140, 224)^2 / 10000
)
# Most basic bubble plot
p <- ggplot(data, aes(x=day, y=value)) +
geom_line() +
xlab("")
p
p + scale_x_date(date_breaks = "1 week", date_labels = "%W")
p + scale_x_date(date_minor_breaks = "2 day")
9+12+3
y<-ts(rnorm(24),start=c(2019,4),frequency=12)
y
ts.plot(y)
m<-c(4:12,1:12,1:3)
m
y<-c(rep(2019,9),rep(2020,12),rep(2021,3))
y<-ts(rnorm(24),start=c(2019,4),frequency=12)
m<-c(4:12,1:12,1:3)
year<-c(rep(2019,9),rep(2020,12),rep(2021,3))
data.frame(y,m,year)
base<-data.frame(y,m,year)
base1 <- base %>%
mutate(time=make_date(year,m,1))
library(recipes)
library(tidyverse)
library(tidyquant)
library(timetk)
library(sweep)
library(forecast)
library(lubridate)
library(recipes)
library(tidyverse)
library(tidyquant)
library(timetk)
library(sweep)
library(forecast)
library(lubridate)
base1 <- base %>%
mutate(time=make_date(year,m,1))
autoplot(base1$y, colour = 'blue3') +
labs(x = "Fecha", y = "Precio",
title= "Precios del Fondo por día desde abril de 2019 hasta marzo de 2021") +
theme_bw()
p <- ggplot(base1, aes(x=time, y=y)) +
geom_line() +
xlab("")
p
p <- ggplot(base1, aes(x=time, y=y)) +
geom_line() +
xlab("")
p
p <- ggplot(base1, aes(x=time, y=y)) +
geom_line() +
xlab("")
p
ggplot(base1, aes(x=time, y=y)) +
geom_line() +
xlab("")
base1 %>%
plot_time_series(time, y,
.facet_ncol = 2,                       #2 columnas
.facet_scales = "free",                #permite escalas diferentes en los gráficos
.interactive = TRUE)
base1 %>%
plot_time_series(time, y,.interactive = FALSE)
?dygraph
install.packages("dygraphs")
y<-xts(x=base1$y,order.by=base1$time)
y<-ts(rnorm(24),start=c(2019,4),frequency=12)
m<-c(4:12,1:12,1:3)
year<-c(rep(2019,9),rep(2020,12),rep(2021,3))
base<-data.frame(y,m,year)
base1 <- base %>%
mutate(time=make_date(year,m,1))
y1<-xts(x=base1$y,order.by=base1$time)
dygraph(y1) %>% dyRangeSelector()
dygraph(y1)
library(dygraphs)
dygraph(y1)
dygraph(y1)%>% dyRangeSelector()
citation("gamlss")
polyroot(c(1, -c(1.8466,-0.8723)))
Mod(polyroot(c(1, -c(1.8466,-0.8723))))
?VAR
??VAR
?vars::VAR
data.frame(y=x1+x2,x1=rnorm(100),x2=rnorm(100))
x1=rnorm(100)
x2=rnorm(100)
y=2*x1+x2
data.frame(y,x1,x2)
data<-data.frame(y,x1,x2)
fit = tslm(v_respuesta ~ trend + season + x1 + x2,data)
library(forecast)
fit = tslm(v_respuesta ~ trend + season + x1 + x2,data)
?tslm
fit = tslm(y ~ trend + season + x1 + x2,data=data)
data.ts<-ts(data)
data.ts
data.ts<-ts(data,frequency=4)
data.ts
fit = tslm(y ~ trend + season + x1 + x2,data=data.ts)
summary(fit)
t=seq(1:100)
y=0.5*t+2*x1+x2
data<-data.frame(y,x1,x2)
data.ts<-ts(data,frequency=4)
library(forecast)
fit = tslm(y ~ trend + season + x1 + x2,data=data.ts)
summary(fit)
forecast( fit, h=12)
TT<-100
TT<-100
x1=rnorm(TT)
x2=rnorm(TT)
t=seq(1:TT)
y=0.5*t+2*x1+x2
data<-data.frame(y,x1,x2)
data.ts<-ts(data,frequency=4)
library(forecast)
fit = tslm(y ~ trend + season + x1 + x2,data=data.ts)
summary(fit)
data.ts
data.ts.train<-window(data.ts,end=c(24,4))
data.ts.train
data.ts.test<-window(data.ts,end=c(25,1))
data.ts.test
data.ts.test<-window(data.ts,start=c(25,1))
data.ts.test
fit = tslm(y ~ trend + season + x1 + x2,data=data.ts.train)
summary(fit)
forecast( fit,  newdata = data.ts.test[-1] , h=12)
data.ts.test[-1]
data.ts.test[,-1]
forecast( fit,  newdata = data.ts.test[,-1] , h=12)
?forecast.ts
predict( fit,  newdata = data.ts.test[,-1] , h=12)
predict( fit,  newdata = data.ts.test[,-1])
?tslm
forecast( fit,  newdata = data.ts.test[,c(2,3))
forecast( fit,  newdata = data.ts.test[,c(2,3)])
data.ts.test[,c(2,3)]
forecast( fit)
forecast(fit,newdata =c(x1))
forecast(fit,newdata =c(x1,x2)
)
forecast(fit,newdata =c(1,1))
forecast(fit,newdata =c(1,1),h=1)
forecast(fit,h=0)
forecast( fit,  newdata = data.ts.testfore[,c(2,3)],ts=FALSE)
forecast( fit,  newdata = data.ts.test[,c(2,3)],ts=FALSE)
forecast( fit,  newdata = data.ts.test[,c(2,3)])
data.ts
rep(1:4,25)
season=rep(1:4,25)
season=as.factor(season)
data<-data.frame(y,x1,x2,t,season)
data.ts<-ts(data,frequency=4)
data.ts
fit = tslm(y ~ trend + season + x1 + x2,data=data.ts.train)
summary(fit)
fit.lm = lm(y ~ t + season + x1 + x2,data=data.ts.train)
t
data.ts.train
data.ts<-ts(data,frequency=4)
data.ts.train<-window(data.ts,end=c(24,4))
data.ts.train
data.ts.test<-window(data.ts,start=c(25,1))
library(forecast)
fit = tslm(y ~ trend + season + x1 + x2,data=data.ts.train)
summary(fit)
fit.lm = lm(y ~ t + season + x1 + x2,data=data.ts.train)
summary(fit.lm)
forecast( fit.lm,  newdata = data.ts.test[,c(2,3,4,5)])
data.ts.test[,c(2,3,4,5)]
forecast( fit.lm,  newdata = data.ts.test[,c(2,3,4,5)])
summary(fit.lm)
data<-data.frame(y,x1,x2)
data.ts<-ts(data,frequency=4)
data.ts.train<-window(data.ts,end=c(24,4))
data.ts.test<-window(data.ts,start=c(25,1))
data.lm<-data.frame(y,x1,x2,t,season)
library(forecast)
fit = tslm(y ~ trend + season + x1 + x2,data=data.ts.train)
summary(fit)
data.lm
data.lm.test <- data.lm[97:100,]
library(forecast)
fit = tslm(y ~ trend + season + x1 + x2,data=data.ts.train)
summary(fit)
fit.lm = lm(y ~ t + season + x1 + x2,data=data.lm.train)
data.lm.train <- data.lm[1:96,]
data.lm.test <- data.lm[97:100,]
fit.lm = lm(y ~ t + season + x1 + x2,data=data.lm.train)
summary(fit.lm)
summary(fit)
forecast( fit.lm,  newdata = data.ts.test[,c(2,3,4,5)])
forecast( fit,  newdata = data.ts.test[,c(2,3,4,5)])
data.ts.test[,c(2,3)]
data.ts.test
forecast( fit,  newdata = data.ts.test[,c(2,3)])
forecast( fit.lm,  newdata = data.lm.test[,c(2,3,4,5)])
require(dlnm);require(NMMAPSlite)
install.packages("NMMAPSlite")
install.packages("NMMAPSlite")
require(dlnm);require(NMMAPSlite)
##############################
# LOAD AND PREPARE THE DATASET
##############################
initDB()
data <- readCity("ny", collapseAge = TRUE)
data <- data[,c("city","date","dow","death","tmpd","dptp","rhum",
"o3tmean","o3mtrend","cotmean","comtrend")]
# TEMPERATURE: CONVERSION TO CELSIUS
data$temp <- (data$tmpd-32)*5/9
# POLLUTION: O3 AND CO AT LAG-01
data$o3 <- data$o3tmean + data$o3mtrend
data$co <- data$cotmean + data$comtrend
data$o301 <- filter(data$o3,c(1,1)/2,side=1)
data$co01 <- filter(data$co,c(1,1)/2,side=1)
# DEW POINT TEMPERATURE AT LAG 0-1
data$dp01 <- filter(data$dptp,c(1,1)/2,side=1)
##############################
# CROSSBASIS SPECIFICATION
##############################
# FIXING THE KNOTS AT EQUALLY SPACED VALUES
range <- range(data$temp,na.rm=T)
ktemp <- range[1] + (range[2]-range[1])/5*1:4
0.5*sqrt(2)
?remove.packages
remove.packages("NanoICPMS.App")
devtools::install_github(repo = "shuwei325/NanoICPMS.App",  build = TRUE,
dependencies = TRUE, force = TRUE,
auth_token="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")
devtools::install_github(repo = "shuwei325/NanoICPMS.App",  build = TRUE,
dependencies = TRUE, force = TRUE,
auth_token="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")
# Load pkg and run application in local browser
library(NanoICPMS.App)
run_NanoICPMS_app()
?sample
sample(1:8)
sample(c(5,4,1))
sample(c(5,4,1),1)
sample(c(1,2,5),1)
sample(c(1,2),1)
sample(c(3,8),1)
sample(c(7,4,3),1)
setwd("D:/Cloud/github/course/SP1633-II21")
